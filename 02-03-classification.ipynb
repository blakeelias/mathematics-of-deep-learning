{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST\n",
    "\n",
    "MNIST is a database of handwritten digits. The images are 28x28 greyscale images (encoded as 784-dimensional vectors in row-major order). There are 60,000 images in the training set, and there are 10,000 images in the test set.\n",
    "\n",
    "Why is there a train-test split? We care about how our function generalizes, and so we want to benchmark its performance on a set of data that it hasn't seen before. Otherwise, a \"perfect\" learning algorithm could just memorize all the data points, but this algorithm wouldn't generalize well.\n",
    "\n",
    "Let's see what one of the MNIST images looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x119fd0470>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119a962e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist.test.images[0].reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the label of this image. The MNIST labels are encoded in one-hot format. There are 10 possible labels, and the vector with label $i$ is the $i$-dimensional vector that has the entry $1$ in the $i$th position and $0$s elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(mnist.test.labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully-connected neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's design a fully-connected neural network to classify MNIST digits. It should take a 784-dimensional input and give a 10-dimensional one-hot encoded probability distribution as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, (None, 28*28)) # batch of inputs\n",
    "y_ = tf.placeholder(tf.float32, (None, 10)) # batch of corresponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this corresponds with the model of a neuron in [ 02-01-notes ]\n",
    "# except this is describing an entire layer, not a single neuron\n",
    "# and we're not including the activation function inside here\n",
    "\n",
    "from scipy.special import expit as sigmoid\n",
    "\n",
    "def fully_connected(x, input_dimension, output_dimension):\n",
    "    w = tf.Variable(tf.random_normal((input_dimension, output_dimension)))\n",
    "    b = tf.Variable(tf.random_normal((output_dimension,)))\n",
    "\n",
    "    # return sigmoid(tf.matmul(x, w) + b)\n",
    "    return tf.matmul(x, w) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a really simple neural network with only one fully-connected layer (the output layer) with 10 neurons.\n",
    "\n",
    "See [ 02-04-notes ] for an architecture diagram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "y = fully_connected(x, int(x.shape[1]), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, $y$ is a 10-dimensional vector, but it's not a probability distribution. We can fix that by applying the softmax function to the logits $y$:\n",
    "\n",
    "$$\\sigma(y)_i = \\frac{e^{y_i}}{\\sum_j e^{y_j}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can define loss as the cross entropy between the true probability distribution (the labels) $p$ and the predicted probability distribution $q$:\n",
    "\n",
    "$$H(p, q) = - \\sum_i p(x) \\log q(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In TensorFlow, we can do both of these in a single step (also needed for numerical stability):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.nn.softmax_cross_entropy_with_logits(logits=y, labels=y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.5).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 60000 training points, so we'll be doing minibatch stochastic gradient descent to train our network (instead of computing gradients over all 60000 data points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "ITERATIONS = 1000\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(ITERATIONS):\n",
    "    x_batch, y_batch = mnist.train.next_batch(BATCH_SIZE)\n",
    "    sess.run(optimizer, {x: x_batch, y_: y_batch})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the accuracy of our network over the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    return np.mean(np.argmax(predictions, 1) == np.argmax(labels, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9006"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = y.eval({x: mnist.test.images})\n",
    "accuracy(predictions, mnist.test.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep fully-connected network\n",
    "\n",
    "Will adding a ton of parameters help us find a better solution? Let's use a deep fully-connected network using layers with 2000, 1000, and 100 neurons in the hidden layers and then 10 neurons in the output layer. Let's use ReLU activation for all the hidden layers. See [ 02-05-notes ] for an architecture diagram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "fc1 = tf.nn.relu(fully_connected(x, 784, 2000))\n",
    "fc2 = tf.nn.relu(fully_connected(fc1, 2000, 1000))\n",
    "fc3 = tf.nn.relu(fully_connected(fc2, 1000, 100))\n",
    "fc4 = fully_connected(fc3, 100, 10)\n",
    "\n",
    "y = fc4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our initial network had ~8,000 parameters. The above network has ~3.5 million parameters, which is over 400x the capacity of the first one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.nn.softmax_cross_entropy_with_logits(logits=y, labels=y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use a fancier optimizer this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 100, batch loss 2169.350586\n",
      "iteration 200, batch loss 3078.282471\n",
      "iteration 300, batch loss 1777.353271\n",
      "iteration 400, batch loss 2797.853760\n",
      "iteration 500, batch loss 744.652100\n",
      "iteration 600, batch loss 1401.535034\n",
      "iteration 700, batch loss 682.831726\n",
      "iteration 800, batch loss 1088.304321\n",
      "iteration 900, batch loss 837.428223\n",
      "iteration 1000, batch loss 1219.963379\n",
      "iteration 1100, batch loss 20.649609\n",
      "iteration 1200, batch loss 593.458252\n",
      "iteration 1300, batch loss 121.415428\n",
      "iteration 1400, batch loss 0.000000\n",
      "iteration 1500, batch loss 481.883667\n",
      "iteration 1600, batch loss 538.229126\n",
      "iteration 1700, batch loss 0.000000\n",
      "iteration 1800, batch loss 883.368103\n",
      "iteration 1900, batch loss 202.963165\n",
      "iteration 2000, batch loss 109.148056\n",
      "iteration 2100, batch loss 355.442108\n",
      "iteration 2200, batch loss 268.422760\n",
      "iteration 2300, batch loss 1745.685059\n",
      "iteration 2400, batch loss 118.511116\n",
      "iteration 2500, batch loss 776.297363\n",
      "iteration 2600, batch loss 194.448807\n",
      "iteration 2700, batch loss 378.894928\n",
      "iteration 2800, batch loss 0.000000\n",
      "iteration 2900, batch loss 98.208122\n",
      "iteration 3000, batch loss 264.550964\n",
      "iteration 3100, batch loss 190.268814\n",
      "iteration 3200, batch loss 36.128956\n",
      "iteration 3300, batch loss 175.076050\n",
      "iteration 3400, batch loss 0.706543\n",
      "iteration 3500, batch loss 116.470703\n",
      "iteration 3600, batch loss 44.162540\n",
      "iteration 3700, batch loss 0.000000\n",
      "iteration 3800, batch loss 120.332184\n",
      "iteration 3900, batch loss 104.955193\n",
      "iteration 4000, batch loss 52.570038\n",
      "iteration 4100, batch loss 486.096161\n",
      "iteration 4200, batch loss 0.976797\n",
      "iteration 4300, batch loss 35.565197\n",
      "iteration 4400, batch loss 129.404221\n",
      "iteration 4500, batch loss 237.603210\n",
      "iteration 4600, batch loss 40.661034\n",
      "iteration 4700, batch loss 110.077049\n",
      "iteration 4800, batch loss 306.295288\n",
      "iteration 4900, batch loss 0.000000\n",
      "iteration 5000, batch loss 0.000000\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 50\n",
    "ITERATIONS = 5000 # this takes ~ 2 minutes on my laptop\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(ITERATIONS):\n",
    "    x_batch, y_batch = mnist.train.next_batch(BATCH_SIZE)\n",
    "    l, _ = sess.run([loss, optimizer], {x: x_batch, y_: y_batch})\n",
    "    if (i+1) % 100 == 0:\n",
    "        print('iteration %d, batch loss %f' % (i+1, np.mean(l)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9497"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = y.eval({x: mnist.test.images})\n",
    "accuracy(predictions, mnist.test.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional neural network\n",
    "\n",
    "Let's design a convolutional neural network to classify MNIST digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x, (-1, 28, 28, 1)) # turn our 784-dimensional vector into a 28x28 image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a convolutional layer\n",
    "\n",
    "def convolve(x, kernel_height, kernel_width, input_channels, output_channels):\n",
    "    w = tf.Variable(tf.random_normal((kernel_height, kernel_width, input_channels, output_channels)))\n",
    "    b = tf.Variable(tf.random_normal((output_channels,)))\n",
    "    \n",
    "    return tf.nn.conv2d(x, w, strides=(1, 1, 1, 1), padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a 2x2 max pooling layer\n",
    "\n",
    "def pool(x):\n",
    "    return tf.nn.max_pool(x, (1, 2, 2, 1), (1, 2, 2, 1), padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network architecture\n",
    "\n",
    "Let's design an architecture with the following layers:\n",
    "\n",
    "* convolution layer with 25 3x3 filters, relu activation\n",
    "* 2x2 max pooling layer\n",
    "* convolution layer with 50 3x3 filters, relu activation\n",
    "* 2x2 max pooling layer\n",
    "* fully-connected layer with 1000 neurons, relu activation\n",
    "* fully-connected output layer (10 neurons)\n",
    "\n",
    "See [ 02-06-notes ] for an architecture diagram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "c1 = tf.nn.relu(convolve(x_image, 3, 3, 1, 25))\n",
    "p1 = pool(c1)\n",
    "c2 = tf.nn.relu(convolve(p1, 3, 3, 25, 50))\n",
    "p2 = pool(c2)\n",
    "p2_flat = tf.reshape(p2, (-1, 7 * 7 * 50))\n",
    "f1 = tf.nn.relu(fully_connected(p2_flat, 7 * 7 * 50, 1000))\n",
    "f2 = fully_connected(f1, 1000, 10)\n",
    "\n",
    "y = f2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This network has approximately 2.5 million parameters. Note that this is about 1 million parameters _fewer_ than the deep fully-connected network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.nn.softmax_cross_entropy_with_logits(logits=y, labels=y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 100, batch loss 678.441711\n",
      "iteration 200, batch loss 487.873505\n",
      "iteration 300, batch loss 365.216248\n",
      "iteration 400, batch loss 543.077942\n",
      "iteration 500, batch loss 422.835388\n",
      "iteration 600, batch loss 207.160034\n",
      "iteration 700, batch loss 112.333633\n",
      "iteration 800, batch loss 61.445522\n",
      "iteration 900, batch loss 319.269226\n",
      "iteration 1000, batch loss 208.393478\n",
      "iteration 1100, batch loss 154.232620\n",
      "iteration 1200, batch loss 57.619312\n",
      "iteration 1300, batch loss 137.592728\n",
      "iteration 1400, batch loss 0.000000\n",
      "iteration 1500, batch loss 0.000000\n",
      "iteration 1600, batch loss 151.628830\n",
      "iteration 1700, batch loss 53.061703\n",
      "iteration 1800, batch loss 47.508213\n",
      "iteration 1900, batch loss 0.000000\n",
      "iteration 2000, batch loss 428.696411\n",
      "iteration 2100, batch loss 15.202549\n",
      "iteration 2200, batch loss 19.581299\n",
      "iteration 2300, batch loss 104.194550\n",
      "iteration 2400, batch loss 158.138931\n",
      "iteration 2500, batch loss 35.327705\n",
      "iteration 2600, batch loss 68.089554\n",
      "iteration 2700, batch loss 8.161329\n",
      "iteration 2800, batch loss 149.537781\n",
      "iteration 2900, batch loss 128.789169\n",
      "iteration 3000, batch loss 128.964584\n",
      "iteration 3100, batch loss 84.068573\n",
      "iteration 3200, batch loss 71.308044\n",
      "iteration 3300, batch loss 26.532066\n",
      "iteration 3400, batch loss 48.586998\n",
      "iteration 3500, batch loss 93.787529\n",
      "iteration 3600, batch loss 85.788124\n",
      "iteration 3700, batch loss 72.229309\n",
      "iteration 3800, batch loss 0.000000\n",
      "iteration 3900, batch loss 8.279316\n",
      "iteration 4000, batch loss 64.022491\n",
      "iteration 4100, batch loss 0.000000\n",
      "iteration 4200, batch loss 0.000000\n",
      "iteration 4300, batch loss 0.000000\n",
      "iteration 4400, batch loss 214.605484\n",
      "iteration 4500, batch loss 0.000000\n",
      "iteration 4600, batch loss 65.929146\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-110477fe5e30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mITERATIONS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'iteration %d, batch loss %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 50\n",
    "ITERATIONS = 5000 # this takes ~ 3.5 minutes on my laptop\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(ITERATIONS):\n",
    "    x_batch, y_batch = mnist.train.next_batch(BATCH_SIZE)\n",
    "    l, _ = sess.run([loss, optimizer], {x: x_batch, y_: y_batch})\n",
    "    if (i+1) % 100 == 0:\n",
    "        print('iteration %d, batch loss %f' % (i+1, np.mean(l)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9725"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = y.eval({x: mnist.test.images})\n",
    "accuracy(predictions, mnist.test.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what some intermediate activations look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1_, conv2_ = sess.run([c1, c2], {x: mnist.test.images[0:1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x119697908>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11987dcf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(2, 2)\n",
    "\n",
    "ax[0, 0].imshow(conv1_[0,:,:,0], cmap='gray')\n",
    "ax[0, 1].imshow(conv1_[0,:,:,1], cmap='gray')\n",
    "ax[1, 0].imshow(conv1_[0,:,:,2], cmap='gray')\n",
    "ax[1, 1].imshow(conv1_[0,:,:,3], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1174d0438>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11972ca58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(2, 2)\n",
    "\n",
    "ax[0, 0].imshow(conv2_[0,:,:,0], cmap='gray')\n",
    "ax[0, 1].imshow(conv2_[0,:,:,1], cmap='gray')\n",
    "ax[1, 0].imshow(conv2_[0,:,:,2], cmap='gray')\n",
    "ax[1, 1].imshow(conv2_[0,:,:,3], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
